# Base model configuration for AgentOne LLM Service
# This file defines all available providers and models
# Profile-specific overrides are in config/models.{profile}.yaml

defaults:
  chat: openrouter/openai/gpt-4o
  vision: openrouter/google/gemini-2.5-flash
  embedding: openai/text-embedding-3-small

providers:
  openrouter:
    name: OpenRouter
    base_url: https://openrouter.ai/api/v1
    models:
      openai/gpt-4o:
        name: GPT-4o
        capabilities: [chat, vision, streaming, tool_calling]
        context_window: 128000
        max_output: 16384
        cost_per_1m_input: 2.5
        cost_per_1m_output: 10.0

      openai/gpt-4-turbo:
        name: GPT-4 Turbo
        capabilities: [chat, vision, streaming, tool_calling]
        context_window: 128000
        max_output: 4096
        cost_per_1m_input: 10.0
        cost_per_1m_output: 30.0

      anthropic/claude-3.5-sonnet:
        name: Claude 3.5 Sonnet
        capabilities: [chat, vision, streaming, tool_calling]
        context_window: 200000
        max_output: 8192
        cost_per_1m_input: 3.0
        cost_per_1m_output: 15.0

      google/gemini-2.5-flash:
        name: Gemini 2.5 Flash
        capabilities: [chat, vision, streaming, tool_calling]
        context_window: 1000000
        max_output: 8192
        cost_per_1m_input: 0.075
        cost_per_1m_output: 0.30

      minimax/minimax-m2.1:
        name: MiniMax M2.1
        capabilities: [chat, streaming, tool_calling]
        context_window: 200000
        max_output: 4096
        cost_per_1m_input: 0.15
        cost_per_1m_output: 1.10

  openai:
    name: OpenAI
    base_url: https://api.openai.com/v1
    models:
      gpt-4o:
        name: GPT-4o
        capabilities: [chat, vision, streaming, tool_calling]
        context_window: 128000
        max_output: 16384
        cost_per_1m_input: 2.5
        cost_per_1m_output: 10.0

      gpt-4-turbo:
        name: GPT-4 Turbo
        capabilities: [chat, vision, streaming, tool_calling]
        context_window: 128000
        max_output: 4096
        cost_per_1m_input: 10.0
        cost_per_1m_output: 30.0

      text-embedding-3-small:
        name: Text Embedding 3 Small
        capabilities: [embedding]
        context_window: 8191
        max_output: 1536
        cost_per_1m_input: 0.02
        cost_per_1m_output: 0.0

  azure_openai:
    name: Azure OpenAI
    api_version: "2024-08-01-preview"
    models:
      gpt-4o:
        name: GPT-4o (Azure)
        deployment: gpt-4o
        capabilities: [chat, vision, streaming, tool_calling]
        context_window: 128000
        max_output: 16384

      gpt-4-turbo:
        name: GPT-4 Turbo (Azure)
        deployment: gpt-4-turbo
        capabilities: [chat, vision, streaming, tool_calling]
        context_window: 128000
        max_output: 4096

  vertex_ai:
    name: Vertex AI (Gemini)
    models:
      gemini-2.5-flash:
        name: Gemini 2.5 Flash
        capabilities: [chat, vision, streaming, tool_calling]
        context_window: 1000000
        max_output: 8192

      gemini-2.5-flash-lite:
        name: Gemini 2.5 Flash Lite
        capabilities: [chat, streaming, tool_calling]
        context_window: 1000000
        max_output: 8192

      gemini-2.5-pro:
        name: Gemini 2.5 Pro
        capabilities: [chat, vision, streaming, tool_calling]
        context_window: 2000000
        max_output: 8192
